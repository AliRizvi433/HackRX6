ğŸš€ LLM-Powered Query Retrieval System â€“ HackRx 6.0
This project is an intelligent, explainable queryâ€“retrieval system built for HackRx 6.0. It enables users to upload insurance/legal/HR/compliance documents (PDF, DOCX, or email), ask natural language questions, and receive accurate answers grounded in document context, along with structured JSON output.

ğŸ§  Features
ğŸ“„ Multi-format Document Support: Accepts PDF, DOCX, and email data (EML)

ğŸ” Semantic Chunking: Documents are split into meaningful segments (clauses/sections)

ğŸ§¬ Embeddings: Uses SentenceTransformer to encode document chunks for semantic search

âš¡ FAISS Vector Search: Fast approximate nearest neighbor search for relevant clauses

ğŸ¤– LLM-Powered Responses: GPT-4 (or fallback) answers questions using retrieved context

ğŸ“¦ Structured JSON Output: Returns relevant clauses, source metadata, and final answer

ğŸ› ï¸ Installation
bash
Copy
Edit
git clone https://github.com/your-org/llm-query-retrieval.git
cd llm-query-retrieval
pip install -r requirements.txt
Ensure you have Python 3.9+ installed and a working OpenAI API Key.

â–¶ï¸ Running the App Locally
bash
Copy
Edit
uvicorn app.main:app --reload --host=0.0.0.0 --port=8000
For production use (no reload):

bash
Copy
Edit
uvicorn app.main:app --host=0.0.0.0 --port=8000
Make sure to export your OpenAI key:

bash
Copy
Edit
export OPENAI_API_KEY="your-key-here"
ğŸ“¤ Example API Request
http
Copy
Edit
POST /api/v1/hackrx/run
Authorization: Bearer <your_token>
Content-Type: application/json

{
  "documents": "<url_to_pdf_or_docx>",
  "questions": [
    "Does this policy cover knee surgery?",
    "What is the waiting period?"
  ]
}
âœ… Sample Output
json
Copy
Edit
{
  "answers": [
    {
      "question": "Does this policy cover knee surgery?",
      "answer": "Yes, knee surgery is covered after a 3-month waiting period.",
      "source_clauses": [
        {
          "text": "Coverage includes orthopedic procedures such as knee surgery...",
          "clause_type": "Coverage",
          "score": 12.4
        }
      ]
    },
    ...
  ]
}
ğŸ§ª How it Works
Document Parsing:

Uses PDFMiner and python-docx to extract clean text

Chunking:

Splits text into logical paragraphs/clauses

Embedding:

Chunks are converted into vector embeddings using all-MiniLM-L6-v2

Indexing:

FAISS is used to store and search the chunks

Query Processing:

For each question, top relevant chunks are retrieved

LLM Response:

GPT-4 (or fallback) generates the final answer grounded in the retrieved context

Structured Output:

Answers are returned alongside metadata for explainability

ğŸŒ Deployment (Replit Compatible)
Make sure your run.sh file includes:

bash
Copy
Edit
python build_chunks.py
python build_index.py
uvicorn app.main:app --host=0.0.0.0 --port=8000
You can deploy on Replit using the "Web Server" template. Paste your OpenAI key in .env.

ğŸ“ Directory Structure
arduino
Copy
Edit
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ chunker.py
â”‚   â”œâ”€â”€ chunk_retriever.py
â”‚   â”œâ”€â”€ clause_classifier.py
â”‚   â”œâ”€â”€ document_parser.py
â”‚   â”œâ”€â”€ responder.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/
â”œâ”€â”€ build_chunks.py
â”œâ”€â”€ build_index.py
â”œâ”€â”€ chunks.pkl
â”œâ”€â”€ faiss.index
â”œâ”€â”€ run.sh
â””â”€â”€ requirements.txt
ğŸ”’ Security Notes
All API calls require a Bearer token in Authorization header

Email and document URLs are sanitized before processing

ğŸ“Œ Submission Details
Webhook URL: https://<your-replit-url>.replit.app/api/v1/hackrx/run

Team Name: <Your Team>

Problem Statement: "Build an LLM-powered intelligent query retrieval system for enterprise docs"